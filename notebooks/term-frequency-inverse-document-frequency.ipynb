{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from itertools import zip_longest\n",
    "from matplotlib.pyplot import figure\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_array\n",
    "from scipy.sparse import find\n",
    "from pickleshare import PickleShareDB\n",
    "\n",
    "df = pd.read_csv('../input/abcnews-date-text.csv')\n",
    "nltk.download('stopwords')\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize and sanitize\n",
    "\n",
    "#tokenize documents into individual words\n",
    "df['tokenized'] = df.headline_text.str.split(' ')\n",
    "\n",
    "#remove short documents from corpus\n",
    "df['length'] = df.tokenized.map(len)\n",
    "df = df.loc[df.length > 1]\n",
    "\n",
    "#use random subset of corpus\n",
    "df=df.sample(frac=0.0001)\n",
    "\n",
    "#flatten all words into single series\n",
    "ex = df.explode('tokenized')\n",
    "\n",
    "#remove shorter words\n",
    "ex = ex.loc[ex.tokenized.str.len() > 2]\n",
    "\n",
    "#remove stopwords\n",
    "ex = ex.loc[~ex.tokenized.isin(stopwords_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ceate dictionary of words\n",
    "\n",
    "#shuffle for sparse matrix visual\n",
    "dictionary = ex.tokenized.drop_duplicates().sample(frac=1)\n",
    "\n",
    "#dataframe with (index/code):word\n",
    "dictionary = pd.Series(dictionary.tolist(), name='words').to_frame()\n",
    "\n",
    "#store code:word dictionary for reverse encoding\n",
    "dictionary_lookup = dictionary.to_dict()['words']\n",
    "\n",
    "#offset index to prevent clash with zero fill\n",
    "dictionary['encode'] = dictionary.index + 1\n",
    "\n",
    "#store word:code dictionary for encoding\n",
    "dictionary = dictionary.set_index('words').to_dict()['encode']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced grouping from group by dataframeto to group by series and aggregated to tuple\n",
    "#improved from 30s to 20s with whole dataset\n",
    "\n",
    "#use dictionary to encode each word to integer representation\n",
    "encode = ex.tokenized.map(dictionary.get).to_frame()\n",
    "encode.index.astype('int')\n",
    "encode.tokenized.astype('int')\n",
    "#un-flatten encoded words back into original documents\n",
    "docs = encode.tokenized.groupby(level=0).agg(tuple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#zero pad x dimention by longest sentence\n",
    "encoded_docs = list(zip(*zip_longest(*docs.to_list(), fillvalue=0)))\n",
    "\n",
    "#convert to sparse matrix\n",
    "encoded_docs = csr_array(encoded_docs, dtype=int)\n",
    "\n",
    "#convert to index for each word\n",
    "row_column_code = find(encoded_docs)\n",
    "\n",
    "#presort by words\n",
    "word_sorted_index = row_column_code[2].argsort()\n",
    "doc_word = np.array([row_column_code[0][word_sorted_index], row_column_code[2][word_sorted_index]])\n",
    "\n",
    "#presort by docs and words\n",
    "doc_word_sorted_index = doc_word[0].argsort()\n",
    "\n",
    "\n",
    "tfidf = pd.DataFrame(np.array([doc_word[0][doc_word_sorted_index], doc_word[1][doc_word_sorted_index]]).T, columns=['doc','word'])\n",
    "\n",
    "#offset code no longer needed after zerofill\n",
    "tfidf.word = tfidf.word - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>word</th>\n",
       "      <th>num_term_in_doc</th>\n",
       "      <th>num_words_in_doc</th>\n",
       "      <th>num_documents</th>\n",
       "      <th>num_docs_with_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>87</td>\n",
       "      <td>464</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>88</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>88</td>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>88</td>\n",
       "      <td>209</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>43</td>\n",
       "      <td>406</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>43</td>\n",
       "      <td>446</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>43</td>\n",
       "      <td>484</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>44</td>\n",
       "      <td>215</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>123</td>\n",
       "      <td>557</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>670 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     doc  word  num_term_in_doc  num_words_in_doc  num_documents  \\\n",
       "0      0    35                1                 6            124   \n",
       "442   87   464                1                 6            124   \n",
       "443   88   178                1                 6            124   \n",
       "444   88   197                1                 6            124   \n",
       "445   88   209                1                 6            124   \n",
       "..   ...   ...              ...               ...            ...   \n",
       "225   43   406                1                 6            124   \n",
       "226   43   446                1                 6            124   \n",
       "227   43   484                1                 6            124   \n",
       "229   44   215                1                 5            124   \n",
       "669  123   557                1                 7            124   \n",
       "\n",
       "     num_docs_with_term  \n",
       "0                     3  \n",
       "442                   2  \n",
       "443                   1  \n",
       "444                   1  \n",
       "445                   1  \n",
       "..                  ...  \n",
       "225                   1  \n",
       "226                   2  \n",
       "227                   2  \n",
       "229                   1  \n",
       "669                   1  \n",
       "\n",
       "[670 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Term Frequency\n",
    "#(num_term_in_doc)/(num_words_in_doc)\n",
    "#Inverse Document Frequency\n",
    "#log(num_documents/num_docs_with_term)\n",
    "#Term Frequency Inverse Document Frequency\n",
    "#(num_term_in_doc)/(num_words_in_doc) * log(num_documents/num_docs_with_term)\n",
    "\n",
    "tfidf = tfidf.groupby(['doc','word']).size().to_frame('num_term_in_doc').reset_index()\n",
    "\n",
    "tfidf['num_words_in_doc'] = tfidf.groupby('doc')['num_term_in_doc'].transform('sum')\n",
    "\n",
    "tfidf['num_documents'] = tfidf.doc.nunique()\n",
    "\n",
    "tfidf['num_docs_with_term'] = tfidf.groupby('word')['doc'].transform('count')\n",
    "\n",
    "tfidf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
